{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UtilityBelt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7OllzGME2VeE7P4qbvJOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BHouwens/MLUtilityBelt/blob/main/UtilityBelt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Belt\n",
        "\n",
        "This is a notebook containing basic utility functions that can be used for data preparation and clean up in ML projects. They're exported to an importable module via `fire` and `notebook2script.py`, as seen in fastai's content. There's no particular order in which the utility functions appear."
      ],
      "metadata": {
        "id": "B9a5YqIVD90M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop Rare Features"
      ],
      "metadata": {
        "id": "1RUiOjw-NPBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export\n",
        "\n",
        "def drop_rare_features(df, thres=.95):\n",
        "  \"\"\"\n",
        "  Drops features in the dataset that have \n",
        "  events that are too rare to be statistically useful\n",
        "  \"\"\"\n",
        "  rare_f = []\n",
        "  print(\"Running with threshold\", thres)\n",
        "  print(\"\")\n",
        "\n",
        "  for col in df.columns:\n",
        "    if df[col].name not in df.select_dtypes(include='category').columns:\n",
        "      freq = df[col].value_counts(normalize=True)\n",
        "      sum_freq = df[col].sum()\n",
        "              \n",
        "      # should be enough to check whether the most freq is dominant\n",
        "      if freq.iloc[0] >= thres:\n",
        "        rare_f.append(col)\n",
        "        print(\"\\x1b[31m{c}: {v}\\x1b[0m\".format(c=col, v=freq.iloc[0]))\n",
        "      else:\n",
        "        print(\"{c}: {v}\".format(c=col, v=freq.iloc[0]))\n",
        "  \n",
        "  df = df.drop(rare_f, axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "IdOSwVxINQ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roulette Test"
      ],
      "metadata": {
        "id": "tpPfZecDL1lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "ALPHA = .05\n",
        "\n",
        "def get_relevant_duplicates(df, dep_var):\n",
        "  \"\"\"\n",
        "  Gets number of duplicates with differing targets\n",
        "  \"\"\"\n",
        "  ind_var = [c for c in df.columns if c != dep_var]\n",
        "\n",
        "  # We need to sift out full duplicate rows\n",
        "  poss_dups = df.duplicated(ind_var).sum()\n",
        "  full_dups = df.duplicated().sum()\n",
        "  return poss_dups - full_dups\n",
        "\n",
        "def roulette_test(df, dep_var, threshold):\n",
        "  \"\"\"\n",
        "  Performs a 1-proportion z-test on df to check for roulette. \n",
        "  Null hypothesis is that the number of duplicates do not \n",
        "  constitute a roulette dataset, in that the number is lower than \n",
        "  the acceptance threshold\n",
        "  \"\"\"\n",
        "  relevant_dups = get_relevant_duplicates(df, dep_var)\n",
        "  if relevant_dups == 0: return False\n",
        "\n",
        "  _, p_val = sm.stats.proportions_ztest(\n",
        "      relevant_dups, len(df), len(df)*threshold, 'smaller')\n",
        "\n",
        "  return p_val > ALPHA"
      ],
      "metadata": {
        "id": "oyTRlf_dL3RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Encoding"
      ],
      "metadata": {
        "id": "HDe-mpyNEu_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnUkfj45D6NY"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "\n",
        "def target_encode(df, target, categorical_features, aggregators = {\"mean\",\"std\"}):\n",
        "  for feature in categorical_features:\n",
        "    aggregation=df.groupby(feature)[target].agg(aggregators)\n",
        "    aggregation.columns=[column+\"_per_{}_{}\".format(feature,target) for column in aggregation.columns.tolist()]\n",
        "\n",
        "    df = df.merge(aggregation, how=\"left\", on=feature)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAF Image Construction"
      ],
      "metadata": {
        "id": "YIkicVZKE7i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export\n",
        "\n",
        "!pip install -Uqq pyts\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pyts.image import GramianAngularField\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GAFConstructor:\n",
        "    \"\"\"\n",
        "    A constructor for GAF images from input DataFrames\n",
        "    \"\"\"\n",
        "    def __init__(self, df, historical_points):\n",
        "      self.df = df\n",
        "      self.column_count = len(df.columns)\n",
        "      self.historical_points = historical_points\n",
        "      self.self.factor = 15\n",
        "      self.img_dim = self.get_img_dimension()\n",
        "    \n",
        "    def build(self, img_stem, path_to_save):\n",
        "      \"\"\"\n",
        "      Main callable function, constructing a GAF image from the \n",
        "      constructor input DataFrame\n",
        "      \"\"\"\n",
        "      if not self.df.isnull().values.any():\n",
        "        self.build_gaf_composites(img_stem, path_to_save)\n",
        "        self.build_single_img(img_stem, path_to_save)\n",
        "      else:\n",
        "        print(\"DataFrame contains null values. Cannot construct GAF images\")\n",
        "    \n",
        "    def get_img_dimension(self):\n",
        "      next_square = self.next_perfect_square()\n",
        "      square_root = math.sqrt(next_square)\n",
        "      return int(self.self.factor * square_root)\n",
        "    \n",
        "    def next_perfect_square(self):\n",
        "      if not self.is_perfect_square():\n",
        "        next_n = math.floor(math.sqrt(self.column_count)) + 1\n",
        "        return next_n * next_n\n",
        "      return self.column_count\n",
        "    \n",
        "    def is_perfect_square(self):\n",
        "      sqrt = math.sqrt(self.column_count)\n",
        "      return int(sqrt) * int(sqrt) == self.column_count\n",
        "    \n",
        "    def get_transform(self, series, transformer):\n",
        "      \"\"\"\n",
        "      Creates and returns a GAF transformation of the input series\n",
        "      \"\"\"\n",
        "      gaf = []\n",
        "\n",
        "      for x in range(0,self.historical_points - self.self.factor):\n",
        "          gaf.append(series[x: x + self.self.factor].to_numpy())\n",
        "      \n",
        "      gaf = np.array(gaf)\n",
        "      return transformer.transform(gaf)\n",
        "    \n",
        "    def build_gaf_composites(self, img_stem, path_to_save):\n",
        "      transformer = GramianAngularField(image_size=self.self.factor, sample_range=(-1, 1), method='summation', overlapping=False)\n",
        "      imgs = {}\n",
        "\n",
        "      for col in self.df.columns:\n",
        "        imgs[col] = self.get_transform(self.df[col], transformer)[0]\n",
        "      \n",
        "      for col in self.df.columns:\n",
        "        plt.imsave('{p}/{f}.png'.format(p=path_to_save, f=\"{i}_{c}\".format(i=img_stem, c=col)), imgs[col])\n",
        "    \n",
        "    def build_single_img(self, img_stem, path_to_save):\n",
        "      \"\"\"\n",
        "      Constructs a single image from input GAF files\n",
        "      \"\"\"\n",
        "      img_paths = [\"{p}/{f}.png\".format(p=path_to_save, f=\"{i}_{c}\".format(i=img_stem, c=col)) for col in self.df.columns]\n",
        "      images = [Image.open(x) for x in img_paths]\n",
        "\n",
        "      new_im = Image.new('RGB', (self.img_dim, self.img_dim))\n",
        "      x_offset = 0\n",
        "      y_offset = 0\n",
        "\n",
        "      for im in images:\n",
        "        if x_offset < self.img_dim:\n",
        "          new_im.paste(im, (x_offset,y_offset))\n",
        "          x_offset += self.factor\n",
        "        else:\n",
        "          y_offset += self.factor\n",
        "          new_im.paste(im, (0,y_offset))\n",
        "          x_offset = self.factor\n",
        "\n",
        "      new_im.save('{p}/{s}.jpg'.format(p=path_to_save, s=img_stem))\n",
        "      for f in img_paths:\n",
        "        os.remove(f)  \n"
      ],
      "metadata": {
        "id": "NaLqACsLE-Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export"
      ],
      "metadata": {
        "id": "7HklaeopNrYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28j_MPvrNsBY",
        "outputId": "7cbd6f75-240d-4ca2-92be-6f6889cc600f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=c6e4c289471213c0baef9d816554d699e66505825cf67c31eff8b4c8b99a9577\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIHQDTSSN4Wu",
        "outputId": "03705d3d-2324-4012-a405-7d3a272ef553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python notebook2script.py \"Colab Notebooks/UtilityBelt.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoiP0dXDNt93",
        "outputId": "d22f2b94-8f78-4f6f-f6d5-052e934e2132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted Colab Notebooks/UtilityBelt.ipynb to Colab Notebooks/exp/nb_UtilityBelt.py\n"
          ]
        }
      ]
    }
  ]
}